{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model presented in the previous project\n",
    "Below is the logistic regression model presented previously in `project.pdf/project.ipynb`. As discussed before, when predicting credit risk, it might be desirable to have a high recall rate for the 'bad' case (y=1). However, the prototype logistic regression presented earlier only have a recall = 0.44, as shown in classification report below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Tenzing Assesment Data Set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['class'].replace('good',0).replace('bad',1).values\n",
    "X = df.drop(['class'], axis = 1)\n",
    "X = pd.get_dummies(X, drop_first=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       210\n",
      "           1       0.65      0.44      0.53        90\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       300\n",
      "   macro avg       0.72      0.67      0.68       300\n",
      "weighted avg       0.75      0.76      0.75       300\n",
      "\n",
      "Confusion matrix:\n",
      " [[188  22]\n",
      " [ 50  40]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "\n",
    "# Fit a logistic regression model to our data\n",
    "prototype_model = LogisticRegression(solver = 'lbfgs', max_iter = 500)\n",
    "prototype_model.fit(X_train, y_train)\n",
    "\n",
    "# Obtain model predictions\n",
    "predicted = prototype_model.predict(X_test)\n",
    "\n",
    "# Print the classifcation report and confusion matrix\n",
    "print('Classification report:\\n', classification_report(y_test, predicted))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve model performance by oversampling minority\n",
    "\n",
    "* As we discussed in previous project, the main reason that causes the low recall rate might be the imbalance of the data set. So we will first try to re-sample the data to achieve the data balance. \n",
    "\n",
    "* Note we should re-sample only after we do the test and train split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "y = df['class'].replace('good',0).replace('bad',1)\n",
    "X = df.drop(['class'], axis = 1)\n",
    "X = pd.get_dummies(X, drop_first=True) \n",
    "\n",
    "# setting up testing and training sets. Note same parameters are set as compared to the moded used earlier.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0,stratify=y)\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    490\n",
       "0    490\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate minority and majority classes\n",
    "good = X[X['class']==0]\n",
    "bad = X[X['class']==1]\n",
    "\n",
    "# upsample minority\n",
    "credit_upsampled = resample(bad,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(good), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([good, credit_upsampled])\n",
    "\n",
    "# check new class counts\n",
    "upsampled['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying logistic regression again with the balanced dataset\n",
    "y_train = upsampled['class']\n",
    "X_train = upsampled.drop('class', axis=1)\n",
    "\n",
    "upsampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "upsampled_pred = upsampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  150  60\n",
       "1   28  62"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, upsampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6888888888888889"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "* We see that up-sampling of the minority class really helps increase the recall rate a lot for 'bad' class, **from 0.44 to 0.69.** \n",
    "* We may also try down-sampling of the majority class and see how the recall rate changes. Also, we may try SMOTE, as mentioned in the previous project. \n",
    "* Note the increase of recall rate for 'bad' class must be at the cost of reducing other metrics such as f1 score, recall rate for 'good' case. We may choose to have a better recall/precision for either 'good' or 'bad', depending on specific business requirement. \n",
    "* Furthermore, we may also combine re-sampling with nonlinear algorithms such as random forest, neural network, support vector machine, etc. In summary, there should be a big room to improve. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
