
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{probabilityStatistics}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Probability Theory}\label{probability-theory}

A major task of probability theory is applying known probability
densities to derive number characteristics such as expectation values,
variances etc. Statistical inference, however, focuses on estimating
parameters of unknown probability densities first, and then apply the
estimated distributions.\\
The following is a summary of some important probability distributions.
The relations among these distributions are also studied in order to
highlight the specific conditions for each specific distribution. For a
more complete list of probability distributions, see the following link:
https://en.wikipedia.org/wiki/List\_of\_probability\_distributions For
their number characteristics, click each individual link.

\subsection{Probability distribution for discrete time and
space}\label{probability-distribution-for-discrete-time-and-space}

\subsubsection{The starting point: Bernoulli
distribution}\label{the-starting-point-bernoulli-distribution}

The PMF is: \[f(x,p) = p^x(1-p)^{1-x}  \quad x \in \{0, 1\}\] Bernoulli
distribution is also called 0-1 distribution. Its expectation and
variance are \(p\) and \(p(1-p)\) respectively.

\subsubsection{\texorpdfstring{Probability of \(x\) occurrences after
\(n\) Bernoulli trials: Binomial
distribution}{Probability of x occurrences after n Bernoulli trials: Binomial distribution}}\label{probability-of-x-occurrences-after-n-bernoulli-trials-binomial-distribution}

\[f(x,n,p) = C_n^x p^x(1-p)^{n-x} \quad x = 0, 1, 2,...n \]

Flipping \(n\) times and assume \(x\) up and \(n-x\) down. There are
\(C_n^x\) such cases, and therefore the above formula.

Conditions are required for the Binomial distribution:\\
* Two possible outcomes for each experiment. The probability for each
outcome is constant.\\
* Each experiment is \textbf{independent} and identical.

These conditions are also required in other five distributions below
that are strongly related binomial distribution. The expectation and
variance are \(np\) and \(np(1-p)\), which are \(n\) times of those of
Bernoulli distribution.

\subsubsection{\texorpdfstring{Probability of first occurrence after
\(n\) Bernoulli trials: Geometric
distribution}{Probability of first occurrence after n Bernoulli trials: Geometric distribution}}\label{probability-of-first-occurrence-after-n-bernoulli-trials-geometric-distribution}

\[f(n,p) = p(1-p)^{n-1} \]

Note we cannot obtain this by setting \(x = 1\) in the binomial
distribution. This is because we only want the \(x=1\) case for the
first time, but not all possible cases where we flip \(n\) times and
have only one occurrence.

\subsubsection{\texorpdfstring{Probability of first \(x\)th occurrences
after \(n\) Bernoulli trials: Negative Binomial
distribution}{Probability of first xth occurrences after n Bernoulli trials: Negative Binomial distribution}}\label{probability-of-first-xth-occurrences-after-n-bernoulli-trials-negative-binomial-distribution}

Also called Pascal distribution. If the \(x\)th occurrence occurs on the
\(n\)th trial, that implies \((x-1)\)th occurrences must have happened
in the previous \((n-1)\) trials. Because these \((x-1)\) occurrences
can occur in any order, the probability of this happening is just
Binomial PMF:\\
\[P(X=x-1; n-1) = C_{n-1}^{x-1}p^{x-1}(1-p)^{n-k}\] Furthermore, the
probability that we will have an occurrence on the \(n\)th trial is
\(p\), therefore \[f(x;p) \equiv P(X=x) = C_{n-1}^{x-1}p^x(1-p)^{n-x}\]
This is true for \(n = x, x+1,....\). For \(n<x\), the probability is
zero.\\
There are alternative formula in the following link
https://en.wikipedia.org/wiki/Negative\_binomial\_distribution.

    \subsection{Probability distribution for continuous time and
space}\label{probability-distribution-for-continuous-time-and-space}

Sometimes we want to know the probability of an event occurring within a
continuous time period or space. If we separate the continuous time or
space into many tiny time or space intervals, then it is possible to
analyze these distributions with the same methods introduced in previous
chapter.

The value of PDF at value x is not the probability of \(P(X=x)\). So PDF
\(f(x)\) can take on values larger than one (but the integral of
\(f(x)\) over any subset of R will be at most one.

\subsubsection{From binomial to Poisson
distribution}\label{from-binomial-to-poisson-distribution}

We now calculate the probability that there would be \(x\) events in
\(t\) time, given some average number of occurrences (\(\lambda = vt\))
in time \(t\). This can be handled with Bernoulli trials. * Divide time
\(t\) period into \(n\) equal intervals. * Probability of occurrence in
any interval is \(p = \lambda / n\).

If the conditions for binomial distribution (see previous chapter) are
satisfied, then the probability that the event will occur \(x\) times
within \(n\) trials is

\[ P(N=x,n) = C_n^x \begin{pmatrix}\frac{\lambda}{n}\end{pmatrix}^x\begin{pmatrix}1-\frac{\lambda}{n}\end{pmatrix}^{n-x} =\frac{\lambda^x}{x!}e^{-\lambda} \quad(n\rightarrow \infty) = \frac{(vt)^x}{x!}e^{-vt}\]

Conditions required to apply Poisson distribution\\
* From its relation to binomial distribution, we know Poisson
distribution must also follow the conditions similar to binomial: (1)
Each event is independent and identical. (2) The mean occurrence rate
\(vt\) or \(\lambda\) (corresponding to \(np\) in binomial) is constant.
\textbf{Note definition of \(\lambda\)}. There might be different
definitions for different distributions. (3). The probability of two or
more occurrences at same time or location is negligible. * From the
derivation above, the formula is true only for very big \(n\). So
Poisson distribution is only true for rare event, or small
\(p = \frac{\lambda}{n}\).

From these conditions we know that when \(n\rightarrow \infty\) and when
\(p\) is small, then binomial distribution can be replaced by Poisson
distribution, which is easier to calculate. However, we must also be
careful of other conditions such as iid, constant rate to apply Poisson
formula. For example, the number of student who arrive at the student
union per minute is not a constant (low rate during class time for
example), and the arrivals of individual students are not independent
(they tends to come in groups).

    \subsubsection{From geometrical to exponential
distribution}\label{from-geometrical-to-exponential-distribution}

When doing experiments in each tiny time interval during a long time
period. What is the probability it takes time duration of t to have the
first occurrence? This is similar to the geometric distribution for e.g.
binomial coin flipping. What is the probability of first occurrence
after n trials? Here taking time duration t is similar to taking how
\(n\) trials.

Assuming \(T_1\) is the time for first event. Then the probability that
first event has not occurred is\\
\[ P(T_1 > t) \equiv P(X = 0; t, v) = \frac{(vt)^0}{0!}e^{-vt}= e^{-vt}\]
The CDF for the occurrence of first event is therefore
\(P(T\leq t ) = 1-e^{-vt}\), and PDF is derivative
\(P(T_1 = t) = ve^{-vt}\)

    \subsubsection{From negative binomial to Gamma
distribution}\label{from-negative-binomial-to-gamma-distribution}

Similar to geometric distribution, we can use Poisson distribution to
derive the Gamma distribution.\\
Assuming \(T_k\) is the time until \(k\)th event. Then the probability
of \(k\) or more occurrences in time \(t\) is

\[ P(T_k \leq t) = \sum_{x=k}^\infty P(X_t = x) = 1 - \sum_{x=0}^{k-1}\frac{(vt)^x}{x!}e^{-vt}\]

Thus the PDF is:\\
\[ P(T_k = t) = \frac{d}{dt}P(T_k \leq t) = \frac{v(vt)^{k-1}}{(k-1)!}e^{-vt}\]

This special form of Gamma distribution give the probability of \(k\)th
event after a time period of \(t\). This is similar to the \(k\)th
events after, e.g., flipping \(n\) times of coins, as described by
negative binomial distribution. \textbf{Note the \(v\) here has the same
definition of \(\lambda\) used in several places discussed later. But
this definition is different from that in the Poisson distribution
before}. General Gamma is given below.

    \subsection{Gamma distribution and its derivative
distributions}\label{gamma-distribution-and-its-derivative-distributions}

\subsubsection{General}\label{general}

https://en.wikipedia.org/wiki/Gamma\_distribution\\
A shape parameter is a kind of numerical parameter of a parametric
family of probability distributions.Such a parameter must affect the
shape of a distribution rather than simply shifting it (as a location
parameter does) or stretching/shrinking it (as a scale parameter does).

The gamma distribution is a two-parameter family of continuous
probability distributions. It is a generalization of the exponential
distribution. The exponential distribution, Erlang distribution, and
chi-squared distribution are special cases of the gamma distribution.
There are \textbf{three different parametrizations} (all positive real
parameters) in common use:\\
* With a shape parameter \(\kappa\) and a scale parameter \(\theta\). *
With a shape parameter \(\alpha = \kappa\) and an inverse scale
parameter \(\beta = \frac{1}{\theta}\), called a rate parameter. * With
a shape parameter \(\kappa\) and a mean parameter
\(\mu = \kappa \theta = \frac{\alpha}{\beta}\)

The parameterization with \(\kappa\) and \(\theta\) appears to be more
common in econometrics and certain other applied fields, where for
example the gamma distribution is frequently used to model waiting
times. The parameterization with \(\alpha\) and \(\beta\) is more common
in Bayesian statistics.

Normally \(\kappa\) or \(\alpha\) can be understood as the number of
events \(k\) in the discrete case. When \(\kappa\) or \(\alpha\) is an
integer, \(\Gamma(\kappa+1) = \kappa!\). The other scale parameter
\(\theta\) or inverse scale parameter \(\beta\) is related to the rate
of the events. In fact the \(\beta\) here is just the rate parameter
\(\lambda\), \(v\), or \(r\) in many other distributions discussed
later. However, note the \(\lambda\) in Poisson distribution is often
defined as \(vt\), so the \(\lambda\) in Poisson case is normally
different from other distributions.

    \subsubsection{Gamma function and gamma
distribution}\label{gamma-function-and-gamma-distribution}

Gamma function is defined as
\(\Gamma(\kappa) = \int_0^{\infty}x^{\kappa - 1}e^{-x}dx \quad \kappa > 0\).
Making the substitution \(y = x/\lambda\) where \(\lambda\) is a
positive real constant, the gamma function becomes
\(\Gamma(\kappa) = \int_0^{\infty}(\lambda y)^{\kappa - 1}e^{-\lambda y}\lambda dy \quad \kappa > 0\).
Divide both sides by \(\Gamma(\kappa)\) yielding
\[ \int_0^{\infty} \frac{\lambda^{\kappa}y^{\kappa-1}e^{-\lambda y}}{\Gamma(\kappa)} dy = 1,\]
which is suitable for a PDF of a random variable.\\
A continuous random variable \(X\) with pdf
\(f(x) = \frac{\lambda^{\kappa}x^{\kappa-1}e^{-\lambda x}}{\Gamma(\kappa)} \quad x > 0\)
for some real constant \(\lambda > 0\) and \(\kappa > 0\) is a
gamma(\(\lambda,\kappa\)) random variable. Check the \(f(x)\) for
\(\kappa > 1, \kappa = 1, \kappa < 1\).

Properties of gamma function:\\
\(\Gamma(n+1) = n! \quad n = 0, 1, ...\)

\(\Gamma(\alpha) = (\alpha-1)\Gamma(\alpha-1) \quad \alpha > 0\)

\(\Gamma(\frac{1}{2}) = \sqrt{\pi}\)

    \subsubsection{Special cases of gamma
distribution}\label{special-cases-of-gamma-distribution}

\paragraph{Exponential distribution}\label{exponential-distribution}

When \(\kappa = 1\)\\
\[ f(x) = \lambda e^{-\lambda x} \quad x>0\] Comparing to
\(P(T_1 = t) = ve^{-vt}\) obtained earlier, the \(\lambda\) here is just
the rate \(v\), or sometimes denoted as \(r\). Both \(v\) and \(r\) are
rate and have a dimension of 1 over time. However, the \(\lambda\) in
the Poisson distribution before is defined as \(\lambda = vt = rt\). So
the \(\lambda\) there is different from the \(\lambda\) here. \textbf{Be
careful of this point}. In many places, \(\lambda, v, r\) etc., have the
same meaning for rate. However, in Poisson case, it is often defined as
\(vt\) or \(rt\).

\paragraph{Erlang distribution}\label{erlang-distribution}

When \(\kappa\) is a positive integer \(k\)
\[f(x) = \frac{\lambda^{k}x^{k-1}e^{-\lambda x}}{(k-1)!} \quad x > 0\]
If \(X_1, X_2,...X_k\) are iid exponential (\(\lambda\)) random
variable, then \(X_1+X_2+...+X_k\) \textasciitilde{}
Erlang(\(\lambda, k\)). \textbf{Note the definition of \(\lambda\) here
is same as an example later, but different from that of Poisson}.

\paragraph{\texorpdfstring{\(\chi^2\)
distribution}{\textbackslash{}chi\^{}2 distribution}}\label{chi2-distribution}

When \(\kappa\) is \(k/2\), where \(k\) is a parameter known as the
degrees of freedom, and \(\lambda = 1/2\)
\[f(x) = \frac{x^{k/2-1}e^{-x/2}}{\Gamma(k/2)2^{k/2}} \quad x>0\]

The \(\chi^2\) distribution is related to the standard normal
distribution. If a random variable \(Z\) has the standard normal
distribution, then \(Z^2\) has the \(\chi^2\) distribution with one
degree of freedom. If \(Z_1, Z_2,...Z_k\) are independent standard
normal variables, then \(Z_1^2+Z_2^2+...+Z_k^2\) has a \(\chi^2\)
distribution with \(k\) degrees of freedom, as described by the PDF
above.

    \subsubsection{Gamma-distribution related
application}\label{gamma-distribution-related-application}

If the events are occurring according to the Poisson distribution the
time till the occurrence of the first event is described by the
exponential distribution. The time till the occurrence of the second
event is described by the Gamma distribution with \(k =2\) (summation of
the time intervals between two consecutive events). Comparing this to
the discrete counterparts of geometric and negative binomial
distributions discussed earlier.\\
For example it is known that under free flow conditions vehicular
arrival pattern follows Poisson distribution. If the mean arrival rate
is 5 vehicles/minute, the headways between consecutive vehicular
arrivals follow exponential distribution with the following PDF
\(f(t) = \frac{1}{5}e^{-5t}\). The time gap between every two vehicles
follows the Gamma distribution with PDF
\(f(t) = \frac{1}{5}(\frac{1}{5}t)e^{-5t}\). The time at which \(k\)th
vehicle arrives at the measurement location follows the PDF
\(f(t) = \frac{1}{5}\frac{(\frac{1}{5}t)^{k-1}}{(k-1)!}e^{-\frac{1}{5}t}\).
Generally this can be written as

\[f(t) = \lambda \frac{(\lambda t)^{k-1}}{\Gamma(k)}e^{-\lambda t}\]

\textbf{Note the definition of \(\lambda\) is different from that in
Poisson distribution.} From above, we can understand that gamma
distribution is a generalization of exponential distribution. To have an
intuition on gamma distribution, imagine the random variable as the
waiting time of some event. Or in the discrete case, the number of total
flips to have the \(kth\) event.

    \subsection{Conditional probability and Bayes
rule}\label{conditional-probability-and-bayes-rule}

\subsubsection{Conditional probability}\label{conditional-probability}

see machine learning notes

\subsubsection{Bayes rule}\label{bayes-rule}

see machine learning notes

\subsubsection{Likelihood function vs
probability}\label{likelihood-function-vs-probability}

https://en.wikipedia.org/wiki/Likelihood\_function

\begin{itemize}
\item
  In statistics, a likelihood function (or just the likelihood) is
  \textbf{a particular function of the parameter} of a statistical model
  given data. In informal contexts, "likelihood" is often used as a
  synonym for "probability". In statistics, the two terms have different
  meanings. \textbf{Probability is function of \(x\) given parameter
  \(\theta\), while is likelihood is function of \(\theta\) given \(x\).
  where \(x\) is the outcome of random variable \(X\).} Likelihood is
  used with each of the four main foundations of statistics:
  frequentism, Bayesianism, likelihoodism, and AIC-based.
\item
  Let \(X\) be a discrete random variable (discrete) with probability
  mass function \(p\) depending on a parameter \(\theta\), then the
  function \(L(\theta \mid x) =p_{\theta }(x)=P_{\theta }(X=x)\)
  considered as a function of \(\theta\), is the likelihood function (of
  \$\theta \$, given the outcome \(x\) of the random variable \(X\). For
  continuous random variable, we have similar definitions.
\item
  An intuitive understanding: Because likelihood is function of
  parameters for a given \(x\), we can think whether \(x\) is LIKELY
  (hence likelihood) to be in the probability distribution of given by
  \(\theta_1\), or \(theta_2\)....A more specific example about biased
  coin tossing in explaining expectation maximization algorithm (by Do
  and Batzoglou, 2008). After a tossing experiment, i.e. the \(x\), we
  may calculate whether this experiment is LIKELY from coin A or coin B,
  which are modeled by different parameters.
\item
  \textbf{Confusion of different notations}

  \begin{itemize}
  \tightlist
  \item
    When judging whether it is a likelihood or a probability, we need
    make sure which is the function argument, but not the specific
    written form. The \(p_{\theta}(x)\) above is more like a function of
    \(x\) given \(\theta\). But it describes a function of \(\theta\)
    given \(x\). So it is a likelihood function.\\
  \item
    When we describe the probability (not likelihood) of "the value
    \(x\) of \(X\) given the parameter value \(\theta\), we often write
    it as \(P(X = x \mid \theta\). Although formally it is like a
    conditional probability, it is not. So instead, we write it as
    \(P(X = x; \theta)\) to emphasize that it is not a conditional
    probability.
  \item
    The likelihood is sometimes written as \(L(\theta \mid x)\) and
    sometimes as \(L(x\mid \theta)\). In other words, the order of the
    appearance of \(\theta\) does not matter. The key is whether
    \(\theta\) is taken as a function argument (variable). Anyway, the
    \(\mid\) sign does not indicate conditional probability.
  \end{itemize}
\item
  In the Maximum Likelihood Estimation (MLE), we are just maximizing the
  likelihood. In deriving many supervised learning algorithms such as
  those in generalized linear models, we usually maximize the likelihood
  with the form \(P(y\mid x; \theta\). Here \(y\) is conditioned on
  \(x\) but parameterized on \(\theta\). However, because the main
  purpose is treating \(P(y\mid x; \theta\) as a function of \(\theta\)
  and find its optimal value, we are maximizing likelihood, rather
  conditional probability.
\item
  In deriving unsupervised learning algorithms with expectation
  maximization (EM), we are still maximizing likelihood but with an
  iterative approach. The likelihood function takes a form of joint
  probability, but essentially we should take it a likelihood as it is a
  function of parameters.
\end{itemize}

    \subsection{Expectation}\label{expectation}

Mean/average (or just expectation), variance, covariance, correlation
etc., are obtained by expectation operator acting on the corresponding
quantity. In other words, they are all 'expectation values'. However,
the 'expectation value' is often used to refer to only the mean or
average of a random variable. Other related concepts include sample
mean, sample variance, sample covariance, covariance matrix, correlation
matrix.

    \subsubsection{Expectation value / mean /
average}\label{expectation-value-mean-average}

\begin{itemize}
\tightlist
\item
  Finite case: \(E(X) = \sum_{i=1}^kx_ip_i\). The expression of
  \(E(x) = \frac{1}{k}\sum_{i=1}{x_i}\) is a special case of
  \(p_i = \frac{1}{k}\).
\item
  Countably infinite case \(E(X) = \sum_{i=1}^{\infty}x_ip_i\), where
  \(\sum_{i=1}^{\infty}|x_i|p_i\) converges.
\item
  Absolutely continuous case \(E(X) = \int_{\mathbb{R}^{}}xf(x)dx\).
\end{itemize}

    \subsubsection{Variance}\label{variance}

The variance of a random variable is the \textbf{expectation value} of
the squared deviation from the mean. * General definition
\(Var(X) = E((x-\mu)^2)\), or \(Var(X) =E(X^2)-(E(X))^2\). * Discrete
random variable \(Var(X) = \sum_{i=1}^np_i(x_i-\mu)^2\), or
\(Var(X) = \sum_{i=1}^np_ix_i^2 - \mu^2\). For a set of \(n\) equally
likely values, \(p_i\) can be replaced by \(\frac{1}{n}\). In this case,
it can also be written as other forms without referring to mean(see
Wikipedia). * Continuous random variable
\(Var(X) = \int_{}^{}(x-\mu)^2f(x)dx = \int_{}^{}x^2f(x)dx -\mu^2\).

    \subsubsection{Covariance}\label{covariance}

The covariance is the expectation value of quantity
\((X-E[X])(Y-E[Y])\). Variance is the special case of covariance where
\(X\) and \(Y\) are same. So variance is also called auto-variance.\\
* General definition
\(cov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]\). * Discrete
variables If the random variable pair \((X,Y)\) can take on values
\((x_i,y_i)\) for \(i = 1,2,...n\) with equal probabilities
\(\frac{1}{n}\), the
\(cov(X) = \frac{1}{n}\sum_{i=1}^n(x_i-E(X))(y_i-E(Y))\). Like variance,
it can also expressed without directly referring to the means. If each
pair of value is not with equal probability, then \(\frac{1}{n}\) need
be replaced with probability \(p_i\) for each pair of data.

    \subsubsection{Correlation}\label{correlation}

It is just the scaled form of covariance.
\(corr{X,Y} = \frac{cov(X,Y)}{\sigma_X\sigma_Y}\).

    \subsubsection{Covariance matrix}\label{covariance-matrix}

\(\mathbf{X} = (X_1,X_2,...X_n)\) is a random vector and \(X_i\) is
scaler random variables. The the covariance matrix \(\Sigma\) is the
matrix whole \((i,j)\) element is
\(\mathbf{\Sigma}_{ij} = \mathrm{cov}(X_i,X_j)\). This is equivalent to
\(\mathbf{\Sigma} = E[(\mathbf{X}-E[\mathbf{X}])(\mathbf{X}-E[\mathbf{X}])^T]\).
Recall that this is similar to the scalar-valued random variable
covariance matrix except the transpose sign.\\
For the reason above, some people call the above
\(Var(\mathbf{X}) = \mathbf{\Sigma}\) as variance because it is the
natural generalization to higher dimensions of the 1-dimensional
variance. But anyway it is commonly called covariance matrix. However,
the notation for the cross-covariance is defined as
\(\mathrm{cov}(\mathbf{X,Y}) = E[(\mathbf{X}-E[\mathbf{X}])(\mathbf{Y}-E[\mathbf{Y}])^T]\).
In this regard, the above covariance matrix is also called
\textbf{variance-covariance} matrix, as the diagonal of the matrix is
variance.

    \subsubsection{Uncorrelated, orthogonal and
independent}\label{uncorrelated-orthogonal-and-independent}

\begin{itemize}
\item
  Assuming X is uniformly distributed in (-1,1), then it can be shown
  \(cov(X,X^2) = 0\). The relationship between \(X\) and \(X^2\) is
  non-linear, while correlation and covariance are measures of linear
  dependence between two variables. This shows two uncorrelated
  variables \textbf{does not in general imply that they are
  independent}.
\item
  Independence implies uncorrelation but uncorrelation DOES NOT imply
  independence. However, when two variables are Gaussian, then
  uncorrelation and independence are equivalent.
\item
  Relation of LINEAR independence, orthogonality and uncorrelation

  \begin{itemize}
  \item
    Linearly independent vectors are those vectors that do not fall
    along the same line; that is, there is no multiplicative constant
    that will expand, contract, or reflect one vector onto the other!
  \item
    Orthogonal vectors are a special case of linearly independent
    variables!
  \item
    Uncorrelated vectors imply that once each variable is centered then
    the vectors are perpendicular.
  \end{itemize}
\end{itemize}

    \begin{figure}
\centering
\includegraphics{attachment:independent_uncorrelated_orthogonal.png}
\caption{independent\_uncorrelated\_orthogonal.png}
\end{figure}

    \subsubsection{Sample mean, variance, covariance
matrix}\label{sample-mean-variance-covariance-matrix}

The definitions of sample mean and sample variance are similar to those
of mean and variance, except people often use the factor of
\(\frac{1}{n}\) for sample variance in order to achieve unbiased
estimation. The next is about sample covariance matrix.\\
https://en.wikipedia.org/wiki/Sample\_mean\_and\_covariance Assume \(X\)
is a \$N\times K \$ matrix describing \(N\) observations with \(K\)
features. The sample mean vector is
\(\bar{\mathbf{x}} = \frac{1}{N}\sum_{i=1}^N\mathbf{x_i}\), where
\(\mathbf{x_i}\) is \textbf{the row vector} of the matrix \(X\) but not
the column vector. We obtain \(K\) component means for the sample mean
vector. The mean is calculated along the column vector. The sample
covariance matrix is
\(Q = \frac{1}{N-1}\sum_{i=1}^N(\mathbf{x_i}-\mathbf{\bar{x}})(\mathbf{x_i}-\mathbf{\bar{x}})^T\).\\
\textbf{Important notes} This is similar to In the derivation of
singular value decomposition (SVD), we calculate the
eigenvalue/eigenvectors of matrix \(A^TA\) and \(AA^T\). If \(A\) is a
\(N\times K\) matrix, then \(A^TA\) is a \(K\times K\) matrix. Also we
have \(A^TA = \sum_{i=1}^N a_ia_i^T\). This is outer-product
multiplication of matrices, where \(a_i\) is the column vector of
\(A^T\) and thus its shape is \(K\times 1\). The process here is exactly
same as the covariance matrix definition except we subtracted mean
there. So in PCA, calculate the eigenvectors of covariance matrix is
same as the calculate the eigenvectors of \(A^TA\), which is the key
step in SVD. Check more detailed comparison between PCA and SVD in other
notes.

    \section{Statistical Inference}\label{statistical-inference}

\subsection{Samples and sampling
distribution}\label{samples-and-sampling-distribution}

\subsubsection{Population}\label{population}

Each individual value in the population is the value of a random
variable. Thus a population corresponds to a random variable. The
density (PDF) and number characteristic of the population is just the
PDF and number of characteristic of a random variable \(X\).

\subsubsection{Random samples}\label{random-samples}

In mathematical terms, given a random variable with distribution F, a
random sample of length \(n\) is a set of \(n\) independent, identically
distributed (iid) random variables \(X_1, X_2, ….X_n\) with distribution
F. By definition, a random sample is already IID, so multiplication rule
of PDF applies. The realizations of these samples \(x_1, x_2, …x_n\) are
not different \(n\) features of an observation in machine learning.
Instead \(x_i\) here indicates a row in a data set.

\subsubsection{How to obtain random and iid
samples}\label{how-to-obtain-random-and-iid-samples}

For finite population, sampling with replacement gives the random sample
(with iid feature). While sampling with replacement is simple in
simulation, it is not convenient in practice. Therefore, we take a
sample as random sample when the sample size \(n\) is much smaller than
the number of elements in population (10\% rule).

\subsubsection{Examples of random
sample}\label{examples-of-random-sample}

\begin{itemize}
\item
  Within a huge population, a real population of a country, we want to
  do sampling on the proportion of people voting for a specific
  candidate. We take a small sample, e.g. 100, as as to satisfy the iid
  requirement, and obtain a sample proportion of \(\hat{p} = 0.55\).
  Note this is not the unknown population proportion \(p\). The sample
  proportion \(\hat{p}\) is a so-called statistics.
\item
  We are measuring the length of an object. It is impossible to
  measuring infinite number of times. So we measuring \(n\) times to
  have a sample, and then calculate the mean of these measurements:
  \(\bar{X} = \frac{\sum_{i=1}^n X_i}{n}\). \(\bar{X}\), called sample
  mean, is a statistic on the sample.
\end{itemize}

\subsubsection{Sampling distribution}\label{sampling-distribution}

As stated earlier, a population corresponds to a random variable \(X\).
Population PDF, population variance, population STD are therefore
defined for the random variable \(X\). For a sample of size \(n\), the
population variance, or STD, will approach constant as \(n\) increases,
but not decreases.

Now consider the distribution of a statistic, sample mean \(\bar{X}\).
Assuming it is a normal distribution (center limit theorem), then it is
easy to obtain its variance as:
\[Var(\bar{X}) = Var(\frac{\sum_{i=1}^n X_i}{n}) = \frac{1}{n^2} Var(\sum_{i=1}^n X_i) = \frac{n \sigma^2}{n^2} = \frac{\sigma^2}{n}\]

Thus the STD of the sampling distribution, i.e. the distribution of
\(\bar{X}\), is \$ \frac{\sigma}{\sqrt{n}}\$. \textbf{The STD of
sampling distribution of a statistic (sample mean here) is called the
standard error (SE).} Note SE decreases as \(n\) increases, which is
different from the population STD. Once SE of a sampling statistic is
calculated, we then can calculate confidence intervals, and do
hypothesis testing for our samplings. From above, we know SE is just a
special STD. When we talk about STD, we refer to the distribution of
population or random variable \(X\). When we talk about SE, we refer to
the distribution of a statistic on a sample, e.g. the sample mean
\(\bar{x}\). In practice, the population variance \(\sigma^2\) is not
known, and thus is replaced by the sample variance \(\hat{\sigma}^2\).
However, be careful that sample variance is not the STD of sampling
distribution. It is just the approximate version of population STD.
Moreover, it is not that any STDs will approach constant when \(n\)
approaches infinity. Only population STD (the STD of random variable X),
or sample variance, approaches constant when \(n\) becomes very large.

In the voting example discussed earlier, the SE is
\(\sqrt{\frac{p(1-p)}{n}}\), where \(p\) is the population proportion
voting for a specific candidate. As it is not known, it is replaced by
the sample proportion.

The above results about sample mean assume that samples are drawn from
an identically, independent distribution (iid). If we drop the
independent assumption but consider an averaged correlation \(p\) among
samples, then we have https://en.wikipedia.org/wiki/Variance,
https://en.wikipedia.org/wiki/Covariance
\[ Var(\bar X) = p\sigma^2 + \frac{1-p}{n}\sigma^2\] Although the
variance is now related to correlation, the idea of using more samples
to reduce variance is still valid. First, we can make sure the samples
from a bootstraping process are as independent as possible. Second the
variance is decreasing as the number of samples increases.

\subsubsection{Examples of sampling
distributions}\label{examples-of-sampling-distributions}

Assuming \(X_1, X_2,...X_n\) is a sample from population
\(N(\mu, \sigma^2)\), and \(\bar{X}\) is the sample mean and \(S^2\) is
sample variance, then we have:\\
* \(\bar{X} \sim N(\mu, \frac{\sigma^2}{n})\)

\begin{itemize}
\item
  \(\frac{(n-1)S^2}{\sigma^2} \sim \chi^2 (n-1)\), \(\bar{X}\) and
  \(S^2\) are independent.
\item
  \(\frac{\bar{X}-\mu}{S/\sqrt{n}} \sim t(n-1)\) Note t-distribution is
  for small-sized sample where we cannot use sample variance to replace
  population variance. Thus we cannot use z-testing but have to use
  t-testing. Because t-testing is for small size and we know that STD of
  sample mean get smaller as size increases, we know that t-distribution
  is just a fatter normal distribution.
\item
  \(\frac{S_1^2/S_2^2}{\sigma_1^2/\sigma_2^2} \sim F(n_1-1, n_2-1)\)
\end{itemize}

    \subsection{Statistics estimation}\label{statistics-estimation}

\subsubsection{Point and interval
estimates}\label{point-and-interval-estimates}

An point estimator is a statistic defined on random samples. Maximum
likelihood estimation (MLE) is a typical way for point estimation.
Normally the population distribution is known but only parameters are
unknown. Unlike the sample mean, the estimator using MLE is sometimes
not an explicit function of \(X_1, X_2…\). Interval estimates are
related to estimating standard error of sampling distribution described
in previous chapter. Two fundamental problems in statistical inference:
estimation and hypothesis testing. The way to estimate can be understood
as calculating the expectation value of a statistic, usually in forms of
calculating maximum likelihood or minimum cost function. Hypothesis
testing is just the application of the point and interval estimates. For
example, in Z-testing, only when we know the interval, then we can do
hypothesis testing with p-value.

\subsubsection{Biased and unbiased
estimate}\label{biased-and-unbiased-estimate}

In statistics, the bias (or bias function) of an estimator is the
difference between this estimator's expected value and the true value of
the parameter being estimated. An estimator or decision rule with zero
bias is called unbiased. Otherwise the estimator is said to be biased.
General MLE estimate of population variance from a sample is biased.
However, we can make this unbiased by multiplying a factor.

\subsubsection{MLE in machine learning}\label{mle-in-machine-learning}

The applications of many machine learning algorithms are essentially
doing statistics estimation. Linear regression is a point estimate (we
estimate a function point in function space). Interval estimate can also
be done with linear regression. The typical parameter estimating
approach, MLE, can be used to derive many supervised learning algorithms
such as linear or logistic regressions. When combined with Bayes rules,
unsupervised learning algorithms such as mixtures of Gaussians/naive
Bayes can be derived with MLE. In fact, a two-step iterative approach
called expectation maximization is used, although the key is still MLE.
See details on these applications of MLE in the notes of machine
learning.

    \subsection{Hypothesis Testing -\/- significance
testing}\label{hypothesis-testing----significance-testing}

    \subsubsection{An intuitive example for hypothesis or significant
testing.}\label{an-intuitive-example-for-hypothesis-or-significant-testing.}

\begin{itemize}
\tightlist
\item
  A neurologist is testing the effect of a drug on response time by
  injecting \(100\) rats with a unit dose of the drug, subjecting each
  to a neurological stimulus, and recording its response time. The
  neurologist knows that the mean response time for rats not injected
  with the drug is \(1.2\) seconds. The mean of the \(100\) injected
  rats' response times is \(1.05\) seconds with a sample standard
  deviation of \(0.5\) seconds. Do you think the drug has an effect on
  response time?\\
\item
  Be careful the sample variance is not the standard deviation of the
  sampling distribution. There is a \(\frac{1}{\sqrt{N}}\) difference.
  Assuming null hypothesis that the drug has no effect, i.e., we assume
  that the observation of small response time \(1.05\)s OR LESS is just
  from measuring volatility. In other words, if we measure a lot of
  average mean response time we can easily obtain a \(1.05\)s or less
  response time even without the drug effect. This is however, just our
  assumption. If we find that probability to obtain small response time
  \(<= 1.05\) is not that appreciable but very tiny, then we should
  reject our null hypothesis.
\end{itemize}

    \subsubsection{\texorpdfstring{The \(p\)
value.}{The p value.}}\label{the-p-value.}

\begin{itemize}
\tightlist
\item
  It is the \textbf{probability} of \textbf{finding the observed, or
  more extreme}, results \textbf{when the null hypothesis of a study
  question is true} -- the definition of 'extreme' depends on how the
  hypothesis is being tested. Three conditions for the definition of p
  value are bold.\\
\item
  The significance level for a given hypothesis test is a value for
  which a \(p\) value less than or equal to is considered statistically
  significant. Typical values for are \(0.1\), \(0.05\), and \(0.01\).
  These values correspond to the probability of observing such an
  extreme value by chance.
\end{itemize}

    \subsubsection{Hypothesis testing with numerical
simulation}\label{hypothesis-testing-with-numerical-simulation}

\begin{itemize}
\tightlist
\item
  The following is a summary of hypothesis testing with numerical
  simulations. Specific exercises are in the notes "Statistical Thinking
  in Python\_Part 2".
\item
  Numerical approach is very flexible in doing hypothesis testing. We
  can do many types of testing without knowing any information of the
  closed form probability densities. Moreover, this can be done with
  almost a standard steps.
\end{itemize}

    \paragraph{General steps of hypothesis testing with numerical
approach}\label{general-steps-of-hypothesis-testing-with-numerical-approach}

\begin{itemize}
\item
  Find a reasonable statistics, which could be the observable, or one of
  several observables, or function of observables. For example, it could
  be mean, mean difference, variance, correlation coefficients, and
  anything else observed from data.
\item
  Once statistics is fixed, we need numerically create many REPLICATES
  of the predetermined statistics. Depending on specific situation,
  permutation and bootstrap approaches are often used to generate
  statistics replicates under the (null) hypothesis. All the generated
  statistics replicates essentially provide a histogram or PDF for a
  random variable corresponding to the statistics. With this PDF or
  histogram we can calculate the \(p\) value in order to do the
  hypothesis testing.
\item
  Calculation of \(p\) value. If the observed statistics is less than
  most of the generated statistics replicates, then we have
  \(p = P(x \leq x_0)\), where \(x_0\) is the observed statistic.
  Otherwise \(p = P(x \geq x_0)\). If \(p\) is very tiny, then it
  indicates that observed \(x_0\) is not from observing volatility. In
  other words, this observation is statistically significant, and thus
  the original null hypothesis should be rejected.
\end{itemize}

    \paragraph{Key points in generating statistics
replicates}\label{key-points-in-generating-statistics-replicates}

\begin{itemize}
\item
  The statistics replicates are generated under the assumption that
  (null) hypothesis is true. Only after we clearly state the null
  hypothesis, we can then generate replicates under this hypothesis.
\item
  When testing the same distribution of two samples, the better way is
  to join the two samples and do permutation. It is more accurate than
  bootstraping. It is not always necessary to joint the samples and then
  perform permutation. If we can assume one same is independent from the
  other, then permutation on one sample is enough.
\item
  Bootstraping, though less accurate, is more flexible. When we cannot
  assume same distributions, but only assume the same other quantities
  such as means, etc., then it is a better way.
\end{itemize}

    \paragraph{A general A/B testing
framework}\label{a-general-ab-testing-framework}

\begin{itemize}
\item
  A/B testing applies to typical problems such as when we examining the
  effect of the upgrading of a website. For example, we may examine the
  whether the spending time of visitors on the website has changed
  before and after the upgrading.
\item
  Some other examples, though not with a before and after features, can
  also be solved with the A/B testing approach. For example, when we
  want to check whether a congress voting results has strong effect of
  party affiliation, whether the strike forces of two frogs has same
  distributions...
\item
  The key idea to solve this type of problems is: we assume 'there is no
  effect', 'there is no party affiliation', 'the strike force is with
  same distribution',.... then we shuffle/permute, or bootstrap to
  obtain statistics replicates, and then calculate \(p\) value to check
  whether the observed results are statistically significant.
\end{itemize}

    \subsubsection{Hypothesis testing using closed-form
PDF}\label{hypothesis-testing-using-closed-form-pdf}

For distributions with closed-form PDF, \(p\) value can be calculated
with integration over the PDF. Although this approach is not as flexible
as the way using numerical simulation, it can provide a lot of insights.
This can be found in standard statistics books.\\
\#\#\#\# Test for the mean of normally distributed population

\paragraph{Test for the variance of normally distributed
population}\label{test-for-the-variance-of-normally-distributed-population}

\begin{itemize}
\tightlist
\item
  SINGLE normal distributed population

  \begin{itemize}
  \tightlist
  \item
    \(\chi^2\) testing. Check an example in
    https://www.khanacademy.org/math/ap-statistics\#tests-significance-ap
    for \(\chi^2\) tests for categorical data.
  \end{itemize}
\item
  Two normal distributed population

  \begin{itemize}
  \tightlist
  \item
    F-testing.
  \end{itemize}
\end{itemize}

\paragraph{HT types include non-normally-distributed
population}\label{ht-types-include-non-normally-distributed-population}

    \section{Cross entropy}\label{cross-entropy}

https://en.wikipedia.org/wiki/Cross\_entropy

    \subsection{Cross-entropy error function and logistic
regression}\label{cross-entropy-error-function-and-logistic-regression}

\[ H(p,q) = \sum_i p_i \text{log}\frac{1}{q_i} = -\sum_i p_i \text{log}q_i = -y\text{log}\hat{y} - (1-y)\text{log}(1-\hat{y})\]
where \(p_i\) and \(p_i\) are respectively the true labels and predicted
labels. We also have \(p_{y=1} = y, p_{y=0} = 1-y\) and
\(q_{y=1} = \hat{y}, q_{y=0} = 1-\hat{y}\).

Log loss provides a steep penalty for predictions that are both wrong
and confident, i.e., a high probability is assigned to the incorrect
class.

    \subsection{Relation to
log-likelihood}\label{relation-to-log-likelihood}

In classification problems we want to estimate the probability of
different outcomes. If the estimated probability of outcome \(i\) is
\(q_i\), while the frequency (empirical probability) of outcome \(i\) in
the training set is \(p_i\), and there are \(N\) samples, then the
likelihood of the training set is \[\Pi_i q_i^{Np_i}\] so the
log-likelihood, divided by \(N\) is
\[ \frac{1}{N}\text{ log }\Pi_i q_i^{Np_i} = \sum_i p_i \text{ log }q_i = -H(p,q)\]
so that maximizing the likelihood is the same as minimizing the cross
entropy.

    \subsection{Relation of surprisal, entropy, cross-entropy and
cross-entropy
loss}\label{relation-of-surprisal-entropy-cross-entropy-and-cross-entropy-loss}

https://medium.com/@vijendra1125/understanding-entropy-cross-entropy-and-softmax-3b79d9b23c8a

\subsubsection{Surprisal}\label{surprisal}

Degree to which you are surprised to see the result. Now, if \(y_i\) is
the probability of \(ith\) outcome then we could represent surprisal as:
\[s = \text{ log } \frac{1}{y_i}\]

    \subsubsection{Entropy:}\label{entropy}

After knowing the surprisal for individual outcomes, we would like to
know surprisal for the event. It would be intuitive to take a weighted
average of surprisals. Taking the probability of each outcome as weight
makes sense because this is how likely each outcome is supposed to
occur. This weighted average of surprisal is nothing but Entropy. If
there are \(n\) outcomes then it could be written as:
\[e = \sum_i y_i\text{ log } \frac{1}{y_i}\]

    \subsubsection{Cross-Entropy:}\label{cross-entropy}

What if each outcome's actual probability is \(p_i\) but someone is
estimating probability as \(q_i\). In this case, each event will occur
with the probability of \(p_i\) but surprisal will be given by \(q_i\)
in its formula (since that person will be surprised thinking that
probability of the outcome is \(q_i\)). Now, weighted average surprisal,
in this case, is nothing but cross entropy and it could be scribbled as:
\[c = \sum_i p_i\text{ log } \frac{1}{q_i}\]

Check the link below for an animation showing how cross entropy is
bigger when \(p_i\) is away from \(q_i\).\\
https://www.desmos.com/calculator/zytm2sf56e


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
